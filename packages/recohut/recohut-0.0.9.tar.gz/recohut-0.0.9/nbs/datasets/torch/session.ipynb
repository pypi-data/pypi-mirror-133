{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp datasets.torch.session"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Session (torch) Datasets\n",
    "> Session-based recommendation datasets in PyTorch Dataset format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "from nbdev.showdoc import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import csv\n",
    "from collections import defaultdict\n",
    "\n",
    "import recohut\n",
    "from recohut.utils.common_utils import download_url\n",
    "\n",
    "import torch\n",
    "from torch.utils import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class Dataset(data.Dataset):\n",
    "    def __init__(self, fpath, maxlen, is_train=True):\n",
    "            [train, valid, test, itemnum] = self.data_partition(fpath)\n",
    "            print(\"Number of sessions:\",len(train)+len(valid)+len(test))\n",
    "            print(\"Number of items:\", itemnum)\n",
    "\n",
    "            action = 0\n",
    "            for i in train:\n",
    "                action += np.count_nonzero(i)\n",
    "            for i in valid:\n",
    "                action += np.count_nonzero(i)\n",
    "            for i in test:\n",
    "                action += np.count_nonzero(i)\n",
    "\n",
    "            print(\"Number of actions:\", action)\n",
    "            print(\"Average length of sessions:\", action/(len(train)+len(valid)+len(test)))\n",
    "\n",
    "            self.data = train if is_train else test\n",
    "            self.maxlen = maxlen\n",
    "            self.itemnum = itemnum\n",
    "            self.is_train = is_train\n",
    "\n",
    "    def __len__(self):\n",
    "            return len(self.data)\n",
    "\n",
    "    def __train__(self, index):\n",
    "            session = np.asarray(self.data[index], dtype=np.int64)\n",
    "            if len(session) > self.maxlen:\n",
    "                session = session[-self.maxlen:]\n",
    "            else:\n",
    "                session = np.pad(session, (self.maxlen-len(session), 0), 'constant', constant_values=0)\n",
    "            curr_seq = session[:-1]\n",
    "            curr_pos = session[1:]\n",
    "            return curr_seq, curr_pos\n",
    "    \n",
    "    def __test__(self, index):\n",
    "            session = self.data[index]\n",
    "            seq = np.zeros([self.maxlen], dtype=np.int64)\n",
    "            idx = self.maxlen - 1\n",
    "            for i in reversed(session[:-1]): #everything except the last one\n",
    "                seq[idx] = i\n",
    "                idx -= 1\n",
    "                if idx == -1: break\n",
    "            return seq, session[-1]-1 #index of the item in the list of all items\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "            if self.is_train:\n",
    "                return self.__train__(index)\n",
    "            else:\n",
    "                return self.__test__(index)\n",
    "\n",
    "    @staticmethod\n",
    "    def data_partition(fname, percentage=[0.1, 0.2]):\n",
    "        itemnum = 0\n",
    "\n",
    "        sessions = defaultdict(list)\n",
    "        session_train = []\n",
    "        session_valid = []\n",
    "        session_test = []\n",
    "        # assume user/item index starting from 1\n",
    "        session_id = 0\n",
    "        f = open(fname, 'r')\n",
    "        total_length = 0\n",
    "        max_length = 0\n",
    "        for line in f:\n",
    "\n",
    "            items = [int(l) for l in line.rstrip().split(',')]\n",
    "\n",
    "            if len(items) < 5: continue\n",
    "            total_length += len(items)\n",
    "\n",
    "            if max_length< len(items):\n",
    "                max_length = len(items)\n",
    "            \n",
    "            itemnum = max(max(items), itemnum)\n",
    "            sessions[session_id].append(items)\n",
    "            session_id += 1\n",
    "\n",
    "        print(\"Avg length:\", total_length/session_id)\n",
    "        print(\"Maximum length:\", max_length)\n",
    "\n",
    "        valid_perc = percentage[0]\n",
    "        test_perc = percentage[1]\n",
    "\n",
    "        total_sessions = session_id\n",
    "        \n",
    "        shuffle_indices = np.random.permutation(range(total_sessions)) #\n",
    "        \n",
    "        train_index = int(total_sessions*(1 - valid_perc - test_perc))\n",
    "        valid_index = int(total_sessions*(1 - test_perc))\n",
    "\n",
    "        if (train_index == valid_index): valid_index += 1 #break the tie\n",
    "        \n",
    "        train_indices = shuffle_indices[:train_index]\n",
    "        valid_indices = shuffle_indices[train_index:valid_index]\n",
    "        test_indices = shuffle_indices[valid_index:]\n",
    "\n",
    "        for i in train_indices:\n",
    "            session_train.extend(sessions[i])\n",
    "        for i in valid_indices:\n",
    "            session_valid.extend(sessions[i])\n",
    "        for i in test_indices:\n",
    "            session_test.extend(sessions[i])\n",
    "        \n",
    "        return [np.asarray(session_train), np.asarray(session_valid), np.asarray(session_test), itemnum]\n",
    "\n",
    "    @staticmethod\n",
    "    def nextitnet_format(fname, maxlen):\n",
    "            \n",
    "        sessions = []\n",
    "\n",
    "        # assume user/item index starting from 1\n",
    "        f = open(fname, 'r')\n",
    "\n",
    "        for line in f:\n",
    "\n",
    "            items = [int(l) for l in line.rstrip().split(',')]\n",
    "\n",
    "            if len(items) < 5: continue\n",
    "            \n",
    "            seq = np.zeros([maxlen], dtype=np.int32)\n",
    "            \n",
    "            idx = maxlen - 1\n",
    "\n",
    "            for i in reversed(items):\n",
    "                seq[idx] = i\n",
    "                idx -= 1\n",
    "                if idx == -1: break        \n",
    "            \n",
    "            sessions.append(seq)\n",
    "            \n",
    "        print(\"number of session:\", len(sessions))\n",
    "\n",
    "        return sessions\n",
    "\n",
    "    @staticmethod\n",
    "    def gru_format(fname, user_train, user_valid, user_test):\n",
    "        \n",
    "        session_id = 0\n",
    "        train = []\n",
    "        for session in user_train:\n",
    "            for item in session:\n",
    "                train.append([session_id, item, 0])\n",
    "            session_id += 1\n",
    "\n",
    "        valid = []\n",
    "        for session in user_valid:\n",
    "            for item in session:\n",
    "                valid.append([session_id, item, 0])\n",
    "            session_id += 1\n",
    "\n",
    "        test = []\n",
    "        for session in user_test:\n",
    "            for item in session:\n",
    "                test.append([session_id, item, 0])\n",
    "            session_id += 1\n",
    "\n",
    "        train_data = pd.DataFrame(train, columns= ['SessionId', 'ItemId', 'Time'])\n",
    "        valid_data = pd.DataFrame(valid, columns= ['SessionId', 'ItemId', 'Time'])\n",
    "        test_data = pd.DataFrame(test, columns= ['SessionId', 'ItemId', 'Time'])\n",
    "\n",
    "        return train_data, valid_data, test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class YoochooseDataset(Dataset):\n",
    "    url = 'https://github.com/RecoHut-Datasets/yoochoose/raw/v3/yoochoose.csv'\n",
    "\n",
    "    def __init__(self, root, maxlen, is_train=True):\n",
    "        fpath = download_url(url=self.url, folder=root)\n",
    "        super().__init__(fpath, maxlen, is_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using existing file yoochoose.csv\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg length: 10.0\n",
      "Maximum length: 10\n",
      "Number of sessions: 80183\n",
      "Number of items: 12936\n",
      "Number of actions: 406979\n",
      "Average length of sessions: 5.075627003230111\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[tensor([[    0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0, 10309, 10309, 10309],\n",
       "         [    0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,   794,  5005,  6891],\n",
       "         [    0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0, 10631,  4104,  9852],\n",
       "         [    0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,  9469,  9486,  9469],\n",
       "         [    0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,   155,  8790,  6931],\n",
       "         [    0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,   770, 11239,  6040],\n",
       "         [    0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0, 11641, 11610, 12033],\n",
       "         [    0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,  8449,  5705, 10331,   170,  8485]]),\n",
       " tensor([[    0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0, 10309, 10309, 10309, 10309],\n",
       "         [    0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,   794,  5005,  6891,  6501],\n",
       "         [    0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0, 10631,  4104,  9852, 10007],\n",
       "         [    0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,  9469,  9486,  9469,  9486],\n",
       "         [    0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,   155,  8790,  6931,  8821],\n",
       "         [    0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,   770, 11239,  6040, 11235],\n",
       "         [    0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0, 11641, 11610, 12033, 11638],\n",
       "         [    0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,  8449,  5705, 10331,   170,  8485, 10332]])]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = YoochooseDataset(root='/content/yoochoose', maxlen=30)\n",
    "\n",
    "sampler = torch.utils.data.DataLoader(dataset, batch_size=8, num_workers=2, pin_memory=True)\n",
    "samples = next(iter(sampler))\n",
    "samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class NowplayingDataset(Dataset):\n",
    "    url = 'https://github.com/RecoHut-Datasets/nowplaying/raw/v3/nowplaying.csv'\n",
    "\n",
    "    def __init__(self, root, maxlen, is_train=True):\n",
    "        fpath = download_url(url=self.url, folder=root)\n",
    "        super().__init__(fpath, maxlen, is_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading https://github.com/RecoHut-Datasets/nowplaying/raw/v3/nowplaying.csv\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg length: 20.0\n",
      "Maximum length: 20\n",
      "Number of sessions: 113918\n",
      "Number of items: 239221\n",
      "Number of actions: 1184815\n",
      "Average length of sessions: 10.400595164943205\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[tensor([[     0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
       "               0, 114002, 113983,  89621, 113960, 113884, 113926, 114000, 113738,\n",
       "          113930,   3168, 113805, 113800, 113789, 113872, 114018, 113881, 113869,\n",
       "          113776,  21568],\n",
       "         [     0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
       "               0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
       "               0,      0,      0,      0,      0,      0,  13653,  11910,  28131,\n",
       "            4896,  33231],\n",
       "         [     0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
       "               0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
       "               0, 217911, 218397,  23439,  23684,  40048,  23439,  22123, 218298,\n",
       "           58345, 218399],\n",
       "         [     0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
       "               0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
       "               0,      0,      0,  16292,   3786,  45272,   3574,  28015,  16926,\n",
       "           27992,  33024],\n",
       "         [     0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
       "               0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
       "           76624,  76624, 113070, 113070,  76624,  76624, 113070, 113070,  76624,\n",
       "           76624, 113070],\n",
       "         [     0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
       "               0, 127696,  39067,  82151,  29706,  29201,  29605,   4791,  29298,\n",
       "          127939,  29456,  29779, 109896,   5945,  73638, 127962,  44011,  29721,\n",
       "          127625, 114913],\n",
       "         [     0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
       "               0,  32544, 155346, 155508, 155074, 155886, 155223, 155360, 155356,\n",
       "          154929, 154914, 155887, 154877, 155115, 155888,  75852, 154969, 155889,\n",
       "          155291, 155890],\n",
       "         [     0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
       "               0,      0,      0,      0,      0,      0,      0,  56331,  56332,\n",
       "           56333,  56334,  56335,  13547,  56336,   7363,  56337,  56338,  56339,\n",
       "            4735,   9554]]),\n",
       " tensor([[     0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
       "          114002, 113983,  89621, 113960, 113884, 113926, 114000, 113738, 113930,\n",
       "            3168, 113805, 113800, 113789, 113872, 114018, 113881, 113869, 113776,\n",
       "           21568, 113925],\n",
       "         [     0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
       "               0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
       "               0,      0,      0,      0,      0,  13653,  11910,  28131,   4896,\n",
       "           33231,   8409],\n",
       "         [     0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
       "               0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
       "          217911, 218397,  23439,  23684,  40048,  23439,  22123, 218298,  58345,\n",
       "          218399, 218330],\n",
       "         [     0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
       "               0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
       "               0,      0,  16292,   3786,  45272,   3574,  28015,  16926,  27992,\n",
       "           33024,  24359],\n",
       "         [     0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
       "               0,      0,      0,      0,      0,      0,      0,      0,  76624,\n",
       "           76624, 113070, 113070,  76624,  76624, 113070, 113070,  76624,  76624,\n",
       "          113070, 113070],\n",
       "         [     0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
       "          127696,  39067,  82151,  29706,  29201,  29605,   4791,  29298, 127939,\n",
       "           29456,  29779, 109896,   5945,  73638, 127962,  44011,  29721, 127625,\n",
       "          114913, 127608],\n",
       "         [     0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
       "           32544, 155346, 155508, 155074, 155886, 155223, 155360, 155356, 154929,\n",
       "          154914, 155887, 154877, 155115, 155888,  75852, 154969, 155889, 155291,\n",
       "          155890, 155891],\n",
       "         [     0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
       "               0,      0,      0,      0,      0,      0,  56331,  56332,  56333,\n",
       "           56334,  56335,  13547,  56336,   7363,  56337,  56338,  56339,   4735,\n",
       "            9554,  56340]])]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = NowplayingDataset(root='/content/nowplaying', maxlen=30)\n",
    "\n",
    "sampler = torch.utils.data.DataLoader(dataset, batch_size=8, num_workers=2, pin_memory=True)\n",
    "samples = next(iter(sampler))\n",
    "samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class DigineticaDataset(Dataset):\n",
    "    url = 'https://github.com/RecoHut-Datasets/diginetica/raw/v4/diginetica.csv'\n",
    "\n",
    "    def __init__(self, root, maxlen, is_train=True):\n",
    "        fpath = download_url(url=self.url, folder=root)\n",
    "        super().__init__(fpath, maxlen, is_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading https://github.com/RecoHut-Datasets/diginetica/raw/v4/diginetica.csv\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg length: 8.777109003245833\n",
      "Maximum length: 70\n",
      "Number of sessions: 63466\n",
      "Number of items: 38970\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/numpy/core/_asarray.py:83: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  return array(a, dtype, copy=False, order=order)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of actions: 557048\n",
      "Average length of sessions: 8.777109003245833\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[tensor([[    0,     0,     0,     0,     0,     0,     0,     0,  2387,  2245,\n",
       "           9141,  2366,  9142,  9143,  3193,  3193,  1726,  1725,  2366,  1722,\n",
       "           2366,  2366,  9144,  3197,  9145,  1722,  9146,  9147,  9146],\n",
       "         [    0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0, 17095, 17101, 17094, 17100, 17096],\n",
       "         [    0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0, 13816,\n",
       "          10789,  9204, 11198, 23151,  8289, 30676,  3372, 30678, 14125],\n",
       "         [    0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,  4814, 10013, 18788,  9285, 14081],\n",
       "         [    0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0, 13064, 36257, 30911, 11052],\n",
       "         [    0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0, 28073, 19585,\n",
       "          17214, 13842, 28815, 28815, 13842, 17214, 19585, 16278, 15659],\n",
       "         [    0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0, 16291, 17881,  5630, 20969, 20969, 20829, 12938],\n",
       "         [    0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,  7298, 25445,  1397, 25445,  7298,  3191,  1735]]),\n",
       " tensor([[    0,     0,     0,     0,     0,     0,     0,  2387,  2245,  9141,\n",
       "           2366,  9142,  9143,  3193,  3193,  1726,  1725,  2366,  1722,  2366,\n",
       "           2366,  9144,  3197,  9145,  1722,  9146,  9147,  9146,  9148],\n",
       "         [    0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0, 17095, 17101, 17094, 17100, 17096, 17102],\n",
       "         [    0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0, 13816, 10789,\n",
       "           9204, 11198, 23151,  8289, 30676,  3372, 30678, 14125, 14124],\n",
       "         [    0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,  4814, 10013, 18788,  9285, 14081,   336],\n",
       "         [    0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0, 13064, 36257, 30911, 11052,  7098],\n",
       "         [    0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0, 28073, 19585, 17214,\n",
       "          13842, 28815, 28815, 13842, 17214, 19585, 16278, 15659, 28072],\n",
       "         [    0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0, 16291, 17881,  5630, 20969, 20969, 20829, 12938, 12938],\n",
       "         [    0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,  7298, 25445,  1397, 25445,  7298,  3191,  1735, 25445]])]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = DigineticaDataset(root='/content/diginetica', maxlen=30)\n",
    "\n",
    "sampler = torch.utils.data.DataLoader(dataset, batch_size=8, num_workers=2, pin_memory=True)\n",
    "samples = next(iter(sampler))\n",
    "samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class LastfmDataset(Dataset):\n",
    "    url = 'https://github.com/RecoHut-Datasets/lastfm/raw/v2/last_fm.csv'\n",
    "\n",
    "    def __init__(self, root, maxlen, is_train=True):\n",
    "        fpath = download_url(url=self.url, folder=root)\n",
    "        super().__init__(fpath, maxlen, is_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading https://github.com/RecoHut-Datasets/lastfm/raw/v2/last_fm.csv\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg length: 17.447849599510228\n",
      "Maximum length: 49\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/numpy/core/_asarray.py:83: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  return array(a, dtype, copy=False, order=order)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of sessions: 196010\n",
      "Number of items: 107391\n",
      "Number of actions: 3419953\n",
      "Average length of sessions: 17.447849599510228\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[tensor([[     0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
       "               0,      0,      0,      0,   3821,     96,   3821,   1600,     96,\n",
       "            3366,   3821,     96,   3366,  18639,   3821,   3280,   3366,     96,\n",
       "            3366,   1600],\n",
       "         [     0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
       "               0,      0,      0,      0,      0,      0,      0,      0,  13864,\n",
       "           35393,  13864,  50765,  13743,  51628,  34165,  44702,  62996,   9504,\n",
       "          106404,  13864],\n",
       "         [     0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
       "               0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
       "               0,      0,      0,      0,      0,      0,      0,   3363,   1875,\n",
       "            2782,   1875],\n",
       "         [   973,   2740,   2712,  17892,   2228,    829,   2740,    128,    744,\n",
       "            1193,   1284,   2755,   1443,   4028,   2712,   7635,    620,   1861,\n",
       "            3978,    790,    916,   1455,    227,  10492,   1257,    633,  29590,\n",
       "            2631,   8419],\n",
       "         [     0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
       "               0,      0,      0,      0,      0,      0,  13576,   9525,   9513,\n",
       "            9857,   9512,   9180,   9335,   1953,   9504,   6466,  19980,  19966,\n",
       "           71404,  90684],\n",
       "         [  8405,   5743,   8106,  35491,    675,   3393,   8239,   3469,   8239,\n",
       "             675,   8405,   8239,   2895,  19781,  16754,   3572,  16754,  16088,\n",
       "             637,   3713,   8171,    675,  15850,   3135,   3713,   8509,   1903,\n",
       "            1900,  13521],\n",
       "         [     0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
       "               0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
       "               0,      0,      0,   8771,   8510,   1409,   3180,   8407,   5464,\n",
       "             479,    707],\n",
       "         [     0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
       "               0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
       "               0,      0,   3366,    987,    988,    987,  47629,    707,   1644,\n",
       "            3775,   1291]]),\n",
       " tensor([[     0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
       "               0,      0,      0,   3821,     96,   3821,   1600,     96,   3366,\n",
       "            3821,     96,   3366,  18639,   3821,   3280,   3366,     96,   3366,\n",
       "            1600,   3366],\n",
       "         [     0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
       "               0,      0,      0,      0,      0,      0,      0,  13864,  35393,\n",
       "           13864,  50765,  13743,  51628,  34165,  44702,  62996,   9504, 106404,\n",
       "           13864,  20385],\n",
       "         [     0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
       "               0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
       "               0,      0,      0,      0,      0,      0,   3363,   1875,   2782,\n",
       "            1875,   9683],\n",
       "         [  2740,   2712,  17892,   2228,    829,   2740,    128,    744,   1193,\n",
       "            1284,   2755,   1443,   4028,   2712,   7635,    620,   1861,   3978,\n",
       "             790,    916,   1455,    227,  10492,   1257,    633,  29590,   2631,\n",
       "            8419,   8555],\n",
       "         [     0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
       "               0,      0,      0,      0,      0,  13576,   9525,   9513,   9857,\n",
       "            9512,   9180,   9335,   1953,   9504,   6466,  19980,  19966,  71404,\n",
       "           90684,  71404],\n",
       "         [  5743,   8106,  35491,    675,   3393,   8239,   3469,   8239,    675,\n",
       "            8405,   8239,   2895,  19781,  16754,   3572,  16754,  16088,    637,\n",
       "            3713,   8171,    675,  15850,   3135,   3713,   8509,   1903,   1900,\n",
       "           13521,   8509],\n",
       "         [     0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
       "               0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
       "               0,      0,   8771,   8510,   1409,   3180,   8407,   5464,    479,\n",
       "             707,    937],\n",
       "         [     0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
       "               0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
       "               0,   3366,    987,    988,    987,  47629,    707,   1644,   3775,\n",
       "            1291,   3775]])]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = LastfmDataset(root='/content/lastfm', maxlen=30)\n",
    "\n",
    "sampler = torch.utils.data.DataLoader(dataset, batch_size=8, num_workers=2, pin_memory=True)\n",
    "samples = next(iter(sampler))\n",
    "samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Author: Sparsh A.\n",
      "\n",
      "Last updated: 2021-12-29 07:54:45\n",
      "\n",
      "Compiler    : GCC 7.5.0\n",
      "OS          : Linux\n",
      "Release     : 5.4.144+\n",
      "Machine     : x86_64\n",
      "Processor   : x86_64\n",
      "CPU cores   : 2\n",
      "Architecture: 64bit\n",
      "\n",
      "torch  : 1.10.0+cu111\n",
      "recohut: 0.0.8\n",
      "csv    : 1.0\n",
      "pandas : 1.1.5\n",
      "numpy  : 1.19.5\n",
      "IPython: 5.5.0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#hide\n",
    "%reload_ext watermark\n",
    "%watermark -a \"Sparsh A.\" -m -iv -u -t -d"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
