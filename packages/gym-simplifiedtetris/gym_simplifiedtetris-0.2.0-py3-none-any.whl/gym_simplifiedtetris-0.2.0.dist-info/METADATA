Metadata-Version: 2.1
Name: gym-simplifiedtetris
Version: 0.2.0
Summary: Simplified Tetris environments compliant with OpenAI Gym's API
Home-page: https://github.com/OliverOverend/gym-simplifiedtetris
Author: Oliver Overend
Author-email: ollyoverend10@gmail.com
License: MIT
Keywords: tetris,gym,openai-gym,reinforcement-learning,research,reward-shaping
Platform: UNKNOWN
Classifier: Intended Audience :: Developers
Classifier: Intended Audience :: Education
Classifier: Intended Audience :: Science/Research
Classifier: Programming Language :: Python :: 3
Classifier: Programming Language :: Python :: 3.8
Classifier: Programming Language :: Python :: 3.9
Classifier: Programming Language :: Python :: 3.10
Classifier: License :: OSI Approved :: MIT License
Classifier: Topic :: Scientific/Engineering :: Artificial Intelligence
Classifier: Topic :: Games/Entertainment :: Puzzle Games
Classifier: Topic :: Software Development :: Libraries :: Python Modules
Requires-Python: >=3.8
Description-Content-Type: text/markdown
Requires-Dist: build (==0.7.0)
Requires-Dist: cloudpickle (==2.0.0)
Requires-Dist: cycler (==0.11.0)
Requires-Dist: dataclasses (==0.6)
Requires-Dist: gym (==0.21.0)
Requires-Dist: kiwisolver (==1.3.2)
Requires-Dist: matplotlib (==3.4.2)
Requires-Dist: numpy (==1.19.5)
Requires-Dist: opencv-python (==4.5.1.48)
Requires-Dist: packaging (==21.3)
Requires-Dist: pandas (==1.3.5)
Requires-Dist: pep517 (==0.12.0)
Requires-Dist: Pillow (==8.4.0)
Requires-Dist: pyparsing (==3.0.6)
Requires-Dist: python-dateutil (==2.8.2)
Requires-Dist: pytz (==2021.3)
Requires-Dist: six (==1.16.0)
Requires-Dist: stable-baselines3 (==1.1.0)
Requires-Dist: tomli (==2.0.0)
Requires-Dist: torch (==1.10.1)
Requires-Dist: tqdm (==4.51.0)
Requires-Dist: typing-extensions (==4.0.1)

<p align="center">
  <img src="https://github.com/OliverOverend/gym-simplifiedtetris/raw/master/assets/20x10_4.gif" width="500">
</p>

<h1 align="center">Gym-SimplifiedTetris </h1>

<p align="center">
  <a href="https://www.codefactor.io/repository/github/oliveroverend/gym-simplifiedtetris">
    <img src="https://img.shields.io/codefactor/grade/github/OliverOverend/gym-simplifiedtetris?color=ff69b4&style=for-the-badge">
  </a>
  <a href="https://pypi.org/">
    <img src="https://img.shields.io/pypi/v/gym-simplifiedtetris?style=for-the-badge">
  </a>
  <a href="https://pypi.org/project/gym-simplifiedtetris/">
    <img src="https://img.shields.io/pypi/pyversions/gym-simplifiedtetris?style=for-the-badge">
  </a>
  <a href="/LICENSE.md">
    <img src="https://img.shields.io/github/license/OliverOverend/gym-simplifiedtetris?color=darkred&style=for-the-badge">
  </a>
  <a href="https://github.com/OliverOverend/gym-simplifiedtetris/commits/dev">
    <img src="https://img.shields.io/github/last-commit/OliverOverend/gym-simplifiedtetris/dev?style=for-the-badge">
  </a>
  <a href="https://github.com/OliverOverend/gym-simplifiedtetris/releases">
    <img src="https://img.shields.io/github/release-date/OliverOverend/gym-simplifiedtetris?color=teal  &style=for-the-badge">
  </a>
  <a href="https://github.com/OliverOverend/gym-simplifiedtetris/issues">
    <img src="https://img.shields.io/github/issues-raw/OliverOverend/gym-simplifiedtetris?color=blueviolet&style=for-the-badge">
  </a>
</p>

<p align="center">
  <a href="https://github.com/OliverOverend/gym-simplifiedtetris/issues/new?assignees=OliverOverend&labels=bug&late=BUG_REPORT.md&title=%5BBUG%5D%3A">Report Bug
  </a>
  Â·
  <a href="https://github.com/OliverOverend/gym-simplifiedtetris/issues/new?assignees=OliverOverend&labels=enhancement&late=FEATURE_REQUEST.md&title=%5BFEATURE%5D%3A">Request Feature
  </a>
  Â·
  <a href="https://github.com/OliverOverend/gym-simplifiedtetris/discussions/new">Suggestions
  </a>
</p>

---

> ðŸŸ¥ Simplified Tetris environments compliant with OpenAI Gym's API

Gym-SimplifiedTetris is a pip installable package that creates simplified Tetris environments compliant with [OpenAI Gym's API](https://github.com/openai/gym). Currently, Gym's API is the field standard for developing and comparing reinforcement learning algorithms.

The environments implemented in this package are simplified because the player must select the column and piece's rotation before the piece is dropped vertically downwards.  If one looks at the previous approaches to the game of Tetris, most of them use this simplified setting.

---

- [1. Installation](#1-installation)
- [2. Usage](#2-usage)
- [3. Agents and environments](#3-agents-and-environments)
- [4. Future work](#4-future-work)
- [5. Acknowledgements](#5-acknowledgements)

## 1. Installation

The package is pip installable:
```bash
pip install gym-simplifiedtetris
```

Or, you can copy the repository by forking it and then downloading it using:

```bash
git clone https://github.com/<YOUR-USERNAME>/gym-simplifiedtetris
```

Packages can be installed using pip:

```bash
cd gym-simplifiedtetris
pip install -r requirements.txt
```

## 2. Usage

The file [examples.py](https://github.com/OliverOverend/gym-simplifiedtetris/blob/master/examples.py) shows two examples of using an instance of the `simplifiedtetris-binary-20x10-4-v0` environment for ten games. You can create an environment using `gym.make`, supplying the environment's ID as an argument.

```python
import gym
import gym_simplifiedtetris

env = gym.make("simplifiedtetris-binary-20x10-4-v0")
obs = env.reset()

# Run 10 games of Tetris, selecting actions uniformly at random.
episode_num = 0
while episode_num < 10:
    env.render()
    action = env.action_space.sample()
    obs, reward, done, info = env.step(action)

    if done:
        print(f"Episode {episode_num + 1} has terminated.")
        episode_num += 1
        obs = env.reset()

env.close()
```

Alternatively, you can import the environment directly:

```python
from gym_simplifiedtetris.envs import SimplifiedTetrisBinaryEnv as Tetris

env = Tetris(grid_dims=(20, 10), piece_size=4)
```

## 3. Agents and environments

Three agents â€” described in [gym_simplifiedtetris/agents](https://github.com/OliverOverend/gym-simplifiedtetris/blob/master/gym_simplifiedtetris/agents) â€” are provided. There are currently 64 environments provided; a description can be found in [gym_simplifiedtetris/envs](https://github.com/OliverOverend/gym-simplifiedtetris/blob/master/gym_simplifiedtetris/envs).

## 4. Future work

- Normalise the observation spaces
- Implement an action space that only permits non-terminal actions to be taken
- Implement more shaping rewards: potential-style, potential-based, dynamic potential-based, and non-potential. Optimise their weights using an optimisation algorithm.

## 5. Acknowledgements

This package utilises several methods from the [codebase](https://github.com/andreanlay/tetris-ai-deep-reinforcement-learning) developed by andreanlay (2020) and the [codebase](https://github.com/Benjscho/gym-mdptetris) developed by Benjscho (2021).


