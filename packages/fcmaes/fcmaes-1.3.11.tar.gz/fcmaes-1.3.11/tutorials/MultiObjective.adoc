:encoding: utf-8
:imagesdir: img
:cpp: C++

== Optimization of multi-objective problems

The code for this tutorial is at 
https://github.com/dietmarwo/fast-cma-es/blob/master/examples/moexamples.py[moexamples.py] and uses 
https://github.com/dietmarwo/fast-cma-es/blob/master/fcmaes/moretry.py[moretry.py] . 
We show:

- How fcmaes single objective optimization algorithms together with a specialized parallel retry implementation
can be applied to compute the pareto front of multi objective problems.
- That good performance of easy benchmark problems (which can be solved by random sampling) is no performance 
indicator for real world problems. 
- How the weighted sum approach can be applied to compute the pareto front thereby parallelizing function evaluations.
- That standard algorithms like NGSAII, if not parallelized, can be several orders of magnitude slower than fcmaes multi objective parallel retry for real world problems. Scaling achieved by parallelization is only part of the story. 

Note that for real world problems the pareto front is not necessarily what you aim for. If our algorithm produces a result containing good but slightly dominated solutions like this:

image::all_ret.rw-top-trumps-biobj_f2i5d122__de_5k320.png[]

it may be a bad idea to compute the pareto front now:

image::front_ret.rw-top-trumps-biobj_f2i5d122__de_5k320.png[]

because:

- Optimization is usually applied to a slightly inaccurate model. 
- It may be a surrogate model designed for fast evaluation,
- or some very expensive to evaluate objectives / constraints are left out, 
- or the constraints could have changed after an optimization run involving very expensive simulations finished. 

With the first result you may reevaluate the limited number of solution vectors using the more accurate / updated
model and only then compute the pareto front. A solution which was slightly dominated at first could come up as
non dominated now. 

=== Experiments with artificial benchmark functions

Note that fcmaes doesn't use dedicated multi-objective algorithms but relies instead on the parallel execution of
single objective algorithms using the weighted sum approach thereby applying random weights. This often works
surprisingly well, specially if the alternative is the single threaded application of a dedicated MO-algorithm. 
As we will see below, for many real world MO-problems from the space flight planning domain involving multiple gravity assist maneuvers
it is the only approach delivering reasonable results.   

Lets first investigate some artificial multi-objective benchmark functions from
https://github.com/DEAP/deap/blob/master/deap/benchmarks/[deap-tests].
See https://www.sciencedirect.com/science/article/pii/S2352711020300911[MOBOpt]
for a description of these functions. As in this paper we chose the well known
benchmark functions Schaffer, Fonseca, Poloni and ZDT1. 

[source,python]
----
class zdt1: 

    def __init__(self, dim):
        self.fun = db.zdt1
        self.bounds = Bounds([0]*dim, [1]*dim)
        self.weight_bounds = Bounds([0.01, 0.01], [1, 1]) 
        self.name = 'zdt1(' + str(dim) + ')'

class schaffer: 

    def __init__(self, dim):
        self.fun = db.schaffer_mo
        self.bounds = Bounds([-1000]*dim, [1000]*dim)
        self.weight_bounds = Bounds([0.01, 0.01], [1, 1]) 
        self.name = 'schaffer(' + str(dim) + ')'

class poloni: 

    def __init__(self, dim):
        self.fun = db.poloni
        self.bounds = Bounds([-math.pi]*dim, [math.pi]*dim)
        self.weight_bounds = Bounds([0.01, 0.01], [1, 1]) 
        self.name = 'poloni(' + str(dim) + ')'

class fonseca: 

    def __init__(self, dim):
        self.fun = db.fonseca
        self.bounds = Bounds([-4]*dim, [4]*dim) 
        self.weight_bounds = Bounds([0.01, 0.01], [1, 1]) 
        self.name = 'fonseca(' + str(dim) + ')'
----

The fcmaes library provides convenience functions for testing parallelized algorithms which generate both
a detailed log file and a diagram showing progress over time / the pareto front: 

[source,python]
----
from fcmaes import moretry

def minimize_plot(problem, opt, name, exp = 2.0, num_retries = 1024, value_limits=None):
    moretry.minimize_plot(problem.name + '_' + name, opt, 
                          problem.fun, problem.bounds, problem.weight_bounds, 
                          num_retries = num_retries, exp = exp, value_limits = value_limits)

def adv_minimize_plot(problem, opt, name, value_limit = math.inf, num_retries = 10240):
    moretry.adv_minimize_plot(problem.name + '_' + name, opt, 
                              problem.fun, problem.bounds, value_limit = value_limit,
                              num_retries = num_retries)
----

First lets check the random search optimization algorithm, 1024 retries, 50000 evaluations each: 

[source,python]
----
mo_retry_plot(zdt1(20), random_search(), '_random')
mo_retry_plot(schaffer(20), random_search(), '_random')
mo_retry_plot(poloni(20), random_search(), '_random', exp=1.0)
mo_retry_plot(fonseca(20), random_search(), '_random', exp=3.0)  
----

- Fonseca function random search, dim = 20, 1024 retries, 50000 evaluations:

image::all_ret.fonseca(20)_random.png[] 

- Poloni function random search, dim = 20, 1024 retries, 50000 evaluations:

image::all_ret.poloni(20)_random.png[] 

Python is surprisingly fast converting these results into a pareto front showing all non-dominated solutions:

- Fonseca function, random search, dim = 20, 1024 retries, 50000 evaluations, pareto front:

image::front_ret.fonseca(20)_random.png[] 

- Poloni function, random search, dim = 20, 1024 retries, 50000 evaluations, pareto front:

image::front_ret.poloni(20)_random.png[]

Lets try two more benchmark problems:

- Schaffer function, random search, dim = 20, 1024 retries, 50000 evaluations:

image::all_ret.schaffer(20)_random.png[]

- Pareto front:

image::front_ret.schaffer(20)_random.png[]

- ZDT1 function, random search, dim = 20, 1024 retries, 50000 evaluations:

image::all_ret.zdt1(20)_random.png[]

- Pareto front:

image::front_ret.zdt1(20)_random.png[]

Wait, the ZDT1 result is not what we expected, may be it helps if we choose a better algorithm?

- ZDT1 function, de-cma sequence, dim = 20, 1024 retries, 50000 evaluations:

image::all_ret.zdt1(20)_decma.png[]

- Pareto front:

image::front_ret.zdt1(20)_decma.png[]

What did we learn so far? For most artificial problems 
no sophisticated optimization algorithm is needed, random search is sufficient.
These "benchmark" functions are designed to show potential flaws in 
multi-objective optimization algorithms.
They don't reflect typical real world problems. You should not predict the
performance of an algorithm for real world problems using these benchmarks. For this reason
lets switch our focus to a 

=== Real World Multi Objective Scenario

Suppose we work at NASA and our task is the planning of the 
https://solarsystem.nasa.gov/missions/cassini/overview/[Cassini] mission to Saturn. 
Fortunately our colleagues at ESA prepared a nice model 
https://www.esa.int/gsp/ACT/projects/gtop/cassini1/[Cassini model] we can adapt to create
a multi objective fitness function. Our boss told us that the overall 
mission time should be < 2000 days. He leaves in a few hours for a big planning meeting and
we need to convince him until then that this is a stupid idea. We need to show him the
tradeoff between fuel consumption and mission time, which means we have to compute the
pareto front for these two competing objectives. Not enough time to feed our Supercomputer,
we only have a fast 16 core desktop (AMD 5950x) available for the analysis. 

We import ESAs single objective Cassini fitness function which determines the overall delta
velocity, which is more or less equivalent to the fuel consumption. The second
objective, the travel time, can easily be derived from the input arguments. 

[source,python]
----
from fcmaes.astro import Cassini1

class cassini1_mo: 

    def __init__(self):
        self.base = Cassini1()
        self.bounds = self.base.bounds
        self.weight_bounds = Bounds([1, 0.01], [100, 1]) # weighting of objectives
        self.name = self.base.name
 
    def fun(self, x):
        dv = self.base.fun(np.array(x)) # delta velocity, original objective (km/s)
        mission_time = sum(x[1:]) # mission time (days)
        y = np.empty(2)
        y[0] = dv       
        y[1] = mission_time
        return y
----

From the https://github.com/dietmarwo/fast-cma-es/blob/master/README.adoc[Readme] we know that the first
objective has an optimal value of 4.93 km/s. It is the easiest of the GTOP problems, solvable 
in under 10 seconds. Will the multi objective version be as easy to solve?
Considering the ZDT1 results above we are skeptical if random sampling will lead us anywhere. 

=== NSGA-II Non-dominated Sorting Genetic Algorithm

But there is an alternative, lets try the well known https://pymoo.org/algorithms/nsga2.html[NSGA-II] algorithm. We adapted the code from https://github.com/ppgaluzio/MOBOpt/blob/master/mobopt/_NSGA-II.py[NSGA-II.py] for this experiment. 

[source,python]
----
def nsgaII_test(problem, fname, NGEN=2000, MU=100, value_limits = None):
    time0 = time.perf_counter() # optimization start time
    name = problem.__class__.__name__ 
    logger().info('optimize ' + name + ' nsgaII') 
    pbounds = np.array(list(zip(problem.bounds.lb, problem.bounds.ub)))
    pop, logbook, front = nsgaII(2, problem.fun, pbounds, NGEN=NGEN, MU=MU) 
    logger().info(name + ' nsgaII time ' + str(dtime(time0)))    
    if not value_limits is None:
        front = np.array(
            [y for y in front if all([y[i] < value_limits[i] for i in range(len(y))])])
    moretry.plot(front, 'nsgaII_' + name + fname)
----

Unfortunately the implementation is single threaded, but NSGA-II solves all our benchmark problems in under 30 seconds:

- Fonseca function, dim = 20, NSGA-II pareto front, NGEN=2000, MU=100:

image::nsgaII_fonseca_front.png[] 

- Poloni function, dim = 20, NSGA-II pareto front, NGEN=2000, MU=100:

image::nsgaII_poloni_front.png[]

- Schaffer function, dim = 20, NSGA-II pareto front, NGEN=2000, MU=100:

image::nsgaII_schaffer_front.png[]

- ZDT1 function, dim = 20, NSGA-II pareto front, NGEN=2000, MU=100:

image::nsgaII_zdt1_front.png[]

Encouraged by the good and fast results for the artificial benchmarks
we hope NSGA-II should also solve the Cassini problem. We expect it to be harder, therefore
we use 120000 generations and a population size of 200.  

- Cassini1 function NSGA-II pareto front, NGEN=120000, MU=200, time = 6587.19 sec:

image::nsgaII_cassini1_mo_120k200_front.png[]

A bit disappointing. Even with 120000 generations and a population size of 200, taking about 6587 seconds,
we still miss the non dominated low dv / high travel time solutions. 

=== fcmaes multi objective parallel retry

Our boss is leaving soon, we are running out of time. Perhaps there is a way to apply our
fast - and parallelizable - single objective algorithms. What if we wrap the multi-objective
function and map it to a single objective one using the weighted sum approach?

[source,python]
----
class mo_wrapper(object):
    """wrapper for multi objective functions applying the weighted sum approach."""
   
    def __init__(self, fun, weights, y_exp=2):
        self.fun = fun  
        self.nobj = len(weights)
        self.weights = weights 
        self.y_exp = y_exp

    def eval(self, x):
        y = self.fun(np.array(x))
        return _avg_exp(self.weights*y, self.y_exp)
        
def _avg_exp(y, y_exp):
    return sum([y[i]**y_exp for i in range(len(y))])**(1.0/y_exp)
----

The idea is now to use random weights - inside defined boundaries - for each optimization retry.
Since these retries are executed in parallel, we can compute much more function evaluations per second
this way. Why do we need a configurable exponent `y_exp` ?
For problems where the pareto front contains very different values for the objectives,
like the Poloni function, we need a low exponent:

- Poloni weighted sum,  y_exp = 1.0, 2000 evals, 1024 retries, 2.7 sec:

image::poloni_1.0_cma_front.png[]

Using a higher exponent we would loose the extreme values at the left.
For real world problems usually we are not interested in results where one of our objectives
has a bad value, we prefer balanced results. For the cassini mission there even may be hard limits 
for both travel time and fuel consumption.  

On the other hand for functions like Fonseca we would have a pareto front "gap"
in the middle for low exponents, therefore we increase it to 3.0:

- Fonseca weighted sum, y_exp = 3.0, 2000 evals, 1024 retries, 4.9 sec:

image::fonseca_3.0_decma_front.png[]

For real world problems `y_exp = 2.0`, the default value usually is a good choice. 

We configure 1024 retries with a maximum of 50000 evaluations. Since our processor supports 32 parallel threads we choose a number of retries dividable by 32. 

[source,python]
----
def minimize_plot(name, optimizer, fun, bounds, weight_bounds, 
                  value_limits = None, num_retries = 1024, 
             exp = 2.0, workers = mp.cpu_count(), logger=logger(), statistic_num = 0):
    time0 = time.perf_counter() # optimization start time
    name += ' ' + optimizer.name
    logger.info('optimize ' + name) 
    xs, ys = minimize(fun, bounds,weight_bounds, 
             value_exp = exp,
             value_limits = value_limits,
             num_retries = num_retries,              
             optimizer = optimizer,
             workers = workers,
             logger=logger, statistic_num = statistic_num)
    retry.plot(ys, 'all_.' + name + '.png', interp=False)
    np.savez_compressed(name, xs=xs, ys=ys)
    xs, front = pareto(xs, ys)
    logger.info(name + ' time ' + str(dtime(time0))) 
    retry.plot(front, 'front_.' + name + '.png')
----

- Cassini weighted sum, 1024 retries, max 50000 evals, BiteOpt algorithm, time = 43.62 sec:

image::front_.Cassini1_bite cpp.png[]
 
- Cassini weighted sum, 1024 retries, max 50000 evals, DE-CMA sequence, time = 31.94 sec:

image::front_.Cassini1_de_cpp _cma_cpp.png[]

Finally non-dominated low-dv solutions with > 6000 travel time show up. This dv-optimum is no trivial 
to find even if formulated as single objective problem. This may be the reason NGSA-II fails here. 

Fcmaes parallel retry outperforms NGSAII by a big margin delivering a superior result. 
The only drawback is that we have to extend the function definition by `weight_bounds` which
sets the bounds for the randomly generated objective weights. The first objective is in m/s, optimum
about 4.7 m/s, the second one in days, optimum > 1000 days. So we define   
`weight_bounds = Bounds([1, 0.01], [100, 1])` to balance the weighted sum: 
Finally we got our Cassini pareto front to convince our boss to allow for a maximal mission time of 2100 days. 

Note that we write of the optimization results before applying ``moretry.pareto` which
can be plotted later if needed:

[source,python]
----
    with np.load('fname.npz') as data:
        xs = data['xs']
        ys = data['ys']
        moretry.plot(ys, 'fname.png', interp=False)
----

- Cassini weighted sum, 1024 retries, max 50000 evals, DE-CMA sequence, all optimization results:

image::all_.Cassini1_de_cpp_cma_cpp.png[]

=== Constraints

What if our problem has to fulfill a list of constraints? They can be converted into objectives:

- Equality:  `a = b` can be converted into objective `abs(a-b)`
- Inequality: `a < b` can be converted into objective `max(0, a-b)`

Use high values as weight bounds, like `[1000, 1000]` allowing for no variation of constraint weights. 
Sometimes it is useful to add a constant penalty `c`:

- Equality:  `a = b` can be converted into objective `abs(a-b) + c if abs(a-b) > 0 else 0`
- Inequality: `a < b` can be converted into objective `a-b + c if a-b > 0 else 0`

=== What if the problem is crazy hard ?

Now we will show what you can do if your problem tests the limits of state of the art single
objective optimizers. Lets have a look at the unconstrained variant
of ESAs https://www.esa.int/gsp/ACT/projects/gtop/tandem/[Tandem] problem, 
another interplanetary trajectory with multiple planet gravity assist maneuvers.
nsgaII_cassini1_mo_20k200_front
Note that it took about 3 years until a 1673.88 kg solution
was discovered by G. Stracquadanio, A. La Ferla and G. Nicosia at University of Catania, see
https://www.esa.int/gsp/ACT/projects/gtop/tandem_unc . As usual we import the GTOP probem
and modify it to take the mission time as second objective into account:

[source,python]
----
from fcmaes.astro import Tandem

class tandem_mo: 

    def __init__(self, constrained=False):
        self.base = Tandem(5, constrained=constrained)
        self.bounds = self.base.bounds
        self.weight_bounds = Bounds([1, 0], [1, 0]) # ignore 2nd objective
        self.name = self.base.name
 
    def fun(self, x):
        final_mass = self.base.fun(np.array(x)) # original objective (-kg)
        mission_time = sum(x[4:8]) # mission time (days)
        y = np.empty(2)
        y[0] = final_mass       
        y[1] = mission_time
        return y
----

Lets start with random search :

- Tandem unconstrained, 10000 retries 100000 evaluations each:

image::front_.Tandem unconstrained_ random.png[]

A billion evaluations for a maximal mass of 22 kg. Quite a distance to the 1673.88 kg optimum. 
A clear indication that this problem is really hard. 

==== NSGA-II

Since we got no chance using the random sample approach - no surprize - lets try NSGA-II next:

[source,python]
----
nsgaII_test(tandem_mo(), '_front.png', NGEN=120000, MU=200, value_limits = [0, 10000])
----

- Tandem unconstrained, NSGA-II pareto front, NGEN=120000, MU=200, time = 7245 sec

image::nsgaII_Tandem_mo_120k200front.png[]

Took over 2 hours, looks very smooth, but unfortunately far away from the real pareto front. Below 3000 days travel
time there are hardly much better solutions, but what caused NSGA-II to avoid longer trajectories? 
The second objective seems to "drag" the algorithm away from high-final-mass solutions. With the weighted sum approach
we have the means to fight this issue.  

==== fcmaes parallel retry

[source,python]
----
    minimize_plot(tandem_mo(), de_cma(100000), '100k10k', num_retries=10240, exp=1.0)
----

- Tandem unconstrained, parallel retry de_cma, 100000 evaluations, 4096 retries, time = 556 sec

image::front_.Tandem unconstrained_6_de_cpp_cma_cpp.png[]

To handle the complexity of the problem we increased the number of evaluations per retry to 100000. 
To fight the "drag" to low mission time solutions 
we completely block the second objective `weight_bounds = Bounds([1, 0], [1, 0])`
and use `exp=1.0` which makes the weighted sum identical to the first objective. This means
that alternatively we directly could have used the single objective Tandem version. We did
not to enable the following

==== Excercise

Experiment with other `weight_bounds` and `exp` settings. You will observe that preserving the
first objective unaltered is crucial to success. Experiment also with other algorithms, 
Bite_cpp(100000, M=16) probably being the strongest - for many other problems even superior - competitor. 

Since we use only the first objective for optimization, why not try the advanced retry which 
uses a smart management of the boundaries depending on previous runs. We feed the algorithm with
`problem.base.fun`, the single objective version of the Tandem problem. 
The pareto front is computed using `ys = np.array([problem.fun(x) for x in xs])`, the 
multi objective Tandem function applied to the optimization result.

[source,python]
----
from fcmaes import advretry

def adv_minimize_plot(name, optimizer, fun, bounds,
                   value_limit = math.inf, num_retries = 1024, logger=logger(), statistic_num = 0):
    time0 = time.perf_counter() # optimization start time
    name += ' ' + optimizer.name
    logger.info('smart optimize ' + name) 
    store = advretry.Store(lambda x:fun(x)[0], bounds, capacity=5000, logger=logger, 
                           num_retries=num_retries, statistic_num = statistic_num) 
    advretry.retry(store, optimizer.minimize, value_limit)
    xs = np.array(store.get_xs())
    ys = np.array([fun(x) for x in xs])
    retry.plot(ys, 'all_smart.' + name + '.png', interp=False)
    np.savez_compressed(name , xs=xs, ys=ys)
    xs, front = pareto(xs, ys)
    logger.info(name+ ' time ' + str(dtime(time0))) 
    retry.plot(front, 'front_smart.' + name + '.png')

adv_minimize_plot(tandem_mo(), de_cma(1000), '_' + str(i) + '_smart', value_limit = -500, num_retries = 100000)
----

- Tandem unconstrained, parallel smart retry de_cma, 100000 retries between 1000 and 50000 evaluations, time = 3360 sec

image::front_smart.Tandem unconstrained 6__2.png[]

Checking all solutions generated we see that the smart parallel retry algorithm found three solutions > 1600 kg. 

image::all_smart.Tandem unconstrained 6__2.png[]

==== Joined forces

A single run may be not sufficient for the pareto front, this is the reason we saved the optimization results
using `np.savez`. Now we can just collect these results to produce the final result using: 

[source,python]
----
def plot_all(folder, fname):
    files = glob.glob(folder + '/*.npz', recursive=True)
    xs = []
    ys = []
    for file in files:
        with np.load(file) as data:
            xs += list(data['xs'])
            ys += list(data['ys'])
    xs = np.array(xs); ys = np.array(ys)         
    xs, front = moretry.pareto(xs, ys)
    moretry.plot(ys, fname + '_all.png', interp=False)
    moretry.plot(front, fname + '_front.png')
----

=== What if the problem is not solvable even as single objective problem ?

In this case we need a surrogate model. 
https://github.com/mlooz/pykep/blob/2edc5db4da9bdd5bec7326353a59c5a796d59ab3/pykep/trajopt/gym/_solar_orbiter.py#L753[_solar_orbiter_udp_1dsm] models 
the https://www.esa.int/Science_Exploration/Space_Science/Solar_Orbiter[Solar Orbiter] mission as a sequence of gravity assist maneuvers with a single deep space maneuver (1DSM) between the planets. Lets assume we use the planet sequence

[source,python]
----
seq=[earth, venus, venus, earth, venus, venus, venus, venus, venus, venus]
----

as in the original mission. The 1DSM solo model is very generic, it allows solutions not considered by the solo
planning team at ESOC. Unfortunately you need future optimization algorithms combined with an incredible amount of
computing power to solve it. So our first goal is to establish the correctness of the model by reproducing 
a number of good solutions we know already from a much simpler model which we fortunately already have here
https://github.com/dietmarwo/fast-cma-es/blob/master/examples/moexamples.py[solo_mgrar_udp.py]. Using 
this "surrogate" model we can compute solutions which are convertible into solutions of the 1DSM model. 
The conversion includes a 
local optimization using the 1dsm model for each surrogate solution because of accuracy issues. 
https://gist.github.com/dietmarwo/86f24e1b9a702e18615b767e226e883f[Here] we listed solutions for both solo models. 
There is no chance to apply existing multi-objective algorithms like NSGA-II neither to the 1DSM nor to the surrogate model. 

Solar Orbiter has not only two, but a number of competing primary objectives:

- Minimal delta velocity / fuel consumption
- Minimal overall travel time
- Maximal inclination relative to the sun equator - we want to investigate the poles of the sun. 
- Minimal - but limited - perhelion. We want to come close but avoid burning our equipment. 

Lets choose the following two objectives:

- First objective: maximal inclination in deg.
- Second objective: minimal travel time in days.

Solar Orbiter 1DSM model, all combined optimization results:

image::solo_mo_all.png[]

- Solar Orbiter 1DSM model, pareto front of all combined optimization results:

image::solo_mo_front.png[]

The pareto front is not very useful here, instead we use all good solutions and select one 
considering secondary objectives like:

- Do we cross a comet halo? The real solo mission does although this was not part of the planning
- Start velocity from earth
- Downlink capability - how fast can data be transferred during the mission

See https://issues.cosmos.esa.int/solarorbiterwiki/download/attachments/44993822/SOL-ESC-RP-05500%20-%20Issue%205r0%2C%20201681029%20-%20Solar%20Orbiter%20CReMA%20Issue%205%20Rev%200.pdf[SOL-ESC-RP-05500] for a detailed description
of the mission goals. 